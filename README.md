My first try on reappering paper Proximy Policy Optimisation. 
My code is written according to Xiaoteng Ma's work.

This PPO reappering is based on Gym environment "CarRacing-v0"
